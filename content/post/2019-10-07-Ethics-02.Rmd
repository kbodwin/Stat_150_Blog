---
title: "Null Results (2)"
author: "Tanned Degus"
date: 2019-10-07
categories: ["Section 02", "Ethics"]
tags: ["Section 02", "P values"]
---

Researchers are always looking for exciting results. Whether it be a study about the link between global warming and the frequency of hurricanes, or a new drug that could be effective in curing cancer, scientists or corporations behind the studies would prefer the more exciting results. Researchers want their experiments to prove something under question or shed light on a new topic rather than showing a null result, either supporting a past study or showing no correlation between the variables. Studies with null results go unpublished nearly 80% of the time, a situation that has become known as the “file drawer” phenomenon.

[Link to Article](https://behavioralscientist.org/the-study-premortem-why-publishing-null-results-is-only-the-first-step/)


<!--more-->

Modern science is largely built on experimentation. We want to know whether two factors are related, or what is the cause of some phenomenon, so we design experiments or perform observational studies to test our explanations. Statistics are how we quantify and interpret our results. In any experiment, the null hypothesis is the default, either the results of a previous experiment or observational study, or an assumed independence between variables. The alternative hypothesis represents a hypothesis we have formed which differs from the null hypothesis, i.e. the currently accepted facts. Once an experiment or observational study has been conducted, the key step is to analyse the data and determine whether our results support our alternative hypothesis. If the probability of our results having happened, assuming the null hypothesis is true, is low enough (often < 0.05), then we reject the status quo, that is the null and and choose our alternative hypothesis instead. However, when the p-value is above our significance level, nothing “happens,” we fail to reject the null hypothesis, and things continue on as they were, or do they?

Researchers are always looking for significant results, results which demonstrate a new relationship between variables, or which rewrite previously accepted facts. In a sense, this is no surprise. Which is more interesting, an experiment that suggests that global warming is contributing to more frequent hurricanes, or an experiment which does not find evidence that global warming is increasing the frequency of hurricanes? Most researchers, let alone the journals which they are trying to publish in, are far more interested in publishing the results of studies like the first, which establish something previously unsuspected or at least unconfirmed. In practice, this is indeed the case, according to research done by a team at Stanford University (published in Science), only 21% of the social science experiments which had null results, were published, as opposed to a publishing rate of 96% for those experiments with strong results (n = 221).

At first blush this might seem like no problem. Why do we care about experiments which didn’t show us anything new? However, here is where we get into the crux of our issue. Null results actually represent interesting and important information, albeit much less dramatic than a low p-value. The knowledge that no relationship appears to exist, and that a relationship has been tested for but was not found, is at least as important as knowing when a relationship exists. And that is precisely what null results represent.

Imagine you’re a biologist who is researching whether cattle-grazing increases the number (= diversity) of annual forbs in rangeland. You could have set up an experimental study, which is generally costly and time-consuming (and you’d have to find someone to loan you some cows!), collect the data, and analyse it. However, suppose that another researcher already did such an experiment 15 years ago, but their results were not significant, in other words, their results did not show a statistically significant increase in the number of annual forbs in rangeland, so they did not publish. If you had access to their results you might be able to get the information you want without the expenditure of anywhere near as much time or money. Generally speaking, publishing null results helps avoid the duplication of work by researchers who are interested in a problem that has already been studied by without significant results.

Perhaps at least as significant (no pun intended!), is the fact that, statistically, we expect 1 out of every 20 trials of an experiment to yield significant results at a significance level of 0.05, when in fact there is no statistically significant relationship there at all! This definitely brings us into an area with ethical concerns. Imagine, for example, that you’ve been commissioned to test a new drug which supposedly cures cancer. You perform a clinical trial, but the result is null. Instead of publishing this result, however, the company directs you to try again, claiming some mistakes must have been made. This process could continue until one of your clinical trials has a significant result, which we expect, on average, once every 20 trials at a significance level of 0.05. If null results were being published, this large number of null results could be noted, and the one significant result could then be properly interpreted as an artifact of chance, but without this context of null results it appears that this drug really is effective at curing cancer. That’s an ethical problem for sure!


Here is a great interactive resource related to this problem: https://projects.fivethirtyeight.com/p-hacking/

Here is an interesting article which takes these ideas a step further: https://behavioralscientist.org/the-study-premortem-why-publishing-null-results-is-only-the-first-step/