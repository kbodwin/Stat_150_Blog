---
title: "Misunderstanding of p-values"
author: "Beamy Rhino"
date: 2019-10-07
categories: ["Section 02", "Data Study"]
tags: ["Section 02", "p-values"]
thumbnailImage: /img/Blog4Pic2.png
thumbnailImagePosition: left
output: html_document
---

This data study proves that some academics don’t  know how p-values are significant. Get it? Significant? A group of students from the University of Valencia in Spain conducted a study  to show the importance of the p-value in academic psychologist research. In their study, they wanted to see how often p-values are misinterpreted; by looking at the outcomes of a test given, they noticed that there are many ways to misinterpret  p-values. These misinterpretations cause many mistakes to be made and cause very misleading conclusions. Want to find out more? Click here!

![](/img/Blog4Pic.png)


The p-value is obviously a vital part of statistical research. A study conducted in 2014 by a research group from the University of Valencia in Spain highlights the importance of the p-value when it comes to academic psychologist research. The research group was made up of four students at the university: Laura Badenes-Ribera, Dolores Frías-Navarro, Héctor Monterde-i-Bort, and Marcos Pascual-Soler. The study was created to bring to light the dangerous errors one can make when p-values are misinterpreted. These misinterpretations can, according to the article, “affect professionals’ decisions and jeopardize the quality of psychological interventions and the accumulation of valid scientific knowledge”; basically, the entire analysis can be damaged.
 
The research group proposes four main types of p-value misinterpretation. When one falsely believes that a p-value indicates a null hypothesis, or confuses the probability of a result with such of a null hypothesis, they have committed an inverse probability fallacy. A replication fallacy is caused by stating that a p-value is the degree of replicability of a result, which is false. This definition means that a replication of the study would have a probability of 1-p of obtaining a statistical significant result, which can drastically affect results. An effect size fallacy is perhaps the most drastic; it is thinking that a p-value directly influences an effect-size of a study. Finally, a clinical or practical significance fallacy links only statistical significance of a study to effect size, which is not true. All of these are heinous errors.
 
The study was conducted by emailing a survey about p-values to 4,066 Spanish academic psychologists, which only 418 (10.26%) responded to. The low response rate could indicate that only these 418 felt confident enough in their abilities to respond. The survey was composed of a demographic section and true/false questions about p-values. Based on the results, the research group concluded that correct interpretation and use of statistics, especially p-values, among Spanish academic psychologists needs to be improved. The plot shown depicts the proportions of the subjects’ correct answers to questions about p-values in terms of probability and in terms of statistics. Each line represents a type of psychologist that responded to the survey. The plot shows that methodology psychologists performed the best probability-wise, but were the only type to not improve when questioned about p-values statistics-wise. The study concludes that, based on the low number of correct answers in the survey overall, academic professors in Spain must be re-educated in statistics in order to create more accurate research and data.
