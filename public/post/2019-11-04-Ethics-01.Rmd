---
title: "Responsible Statistic Education and Common Misinterpretations"
author: "zombie_elephant"
date: 2019-10-07
categories: ["Section 01", "Ethics Topic"]
tags: ["Section 01", "Responsible Statistic Education and Common Misinterpretations"]
thumbnailImage: https://images.theconversation.com/files/162827/original/image-20170328-21243-6xrdpk.jpg?ixlib=rb-1.1.0&q=45&auto=format&w=1200&h=1200.0&fit=crop
thumbnailImagePosition: left
output: html_document
---

An understanding of statistics is necessary to be able to correctly interpret the data we see and understand it’s validity. However, there are many common misunderstandings surrounding statistics and probability. Without an understanding of the validity of  findings, people, even those who have been taught introductory statistics, can be led to false conclusions with real world consequences.



[Responsible Statistic Education and Common Misinterpretations](https://www.ics.uci.edu/~jutts/AmerStat2003.pdf)



Statistics used to be a small area of study, reserved for researchers to analyze their results. However, now, many professions, most notably journalists and medical professionals use it regularly, making a lack of understanding of statistics a real problem.The issues discussed in this article constitute one list of common and important misunderstandings in statistics and probability. One of the reasons we teach everyone how to read and write effectively is to give them the knowledge they need to look at journalism and other messages critically. Yet, while news articles show polls and scientific studies all the time, most people have not been taught how to look at these pieces critically and evaluate their validity. Without an understanding of the validity of  findings, people, even those who have been taught introductory statistics, can be led to false conclusions with real world consequences.
	There are a great number of ways that studies - even those with large sample sizes, or well thought out methods - can mislead the average person. Unfortunately, there is no way to simply explain all of these errors in a simplified, unified theory, so, to build an understanding of them, and help others catch false conclusions, we’ll have to take a look at a number of the most common statistical failures individually as discussed in the article, “What Educated Citizens Should Know About Statistics and Probability.”
	The first revolves around the saying we’ve all heard a thousand times: correlation does not imply causation. Despite the prevalence of this saying, the error persists as one of the most common failures, especially in the ways journalists interpret scientific studies for the public. The root of this is that many scientific studies examine not the results of experiments, but survey data or observed data. Because these studies do not get the chance to affect their subjects and then record the results of the effects, which allows them to demonstrate causation, they can only demonstrate that certain variables tend to go together - they cannot tell why. These correlational studies are still important to science, but, in the hands of unscrupulous journalists, they can be misinterpreted as pointing to one variable causing another.
	Another issue is the difference between a statistically significant difference and a practically important difference. When most people hear “statistically significant”, they think that it means there is a somewhat large effect that should be seen as important. However, with a powerful enough study, even a tiny effect, that people do not realistically need to worry about, can be determined to be statistically significant. Because of this, one should always look not only for significance, but effect size when interpreting a study. 
	People also make the mistake of seeing a null result as an indication that a study has found that there is no effect from what they were studying. However, when viewed through the correct statistical lens, a null result could mean that the study was merely not powerful enough to demonstrate an effect that does actually exist.
	Better understood, yet still prevalent, are survey biases. Whether the wording of a question is misleading, or one question affects how someone thinks when answering the next, most people understand that people cannot always be taken at their word. Respondents are prone to giving the most socially desirable responses, or the responses they think the interviewer wants to hear. These biases can easily invalidate surveys, however, we still often use surveys because, for many tasks, there is simply no replacement for the data they provide.
	Lastly, when examining articles about crazy coincidences, people, including the ones writing the pieces, misinterpret the likelihood that an unlikely event would happen. For example, you might see a headline about “Man rolling a dice rolls 8 6’s in a row, in a stunning 1/1670616 odds”. The title would suggest that the likelihood that this would happen is less than one in a million. However, if we consider that millions of people roll dice every day, this headline becomes much less impressive. It starts looking even less impressive when you consider that it would look equally amazing to roll a 1 8 times in a row, or any other number. Though we don’t see articles about dice typically, other articles about coincidences between twins separated at birth, or similar topics, are often much less crazy when you think about the underlying statistics behind them. So, be careful with your interpretations of statistics - there are so many pitfalls to avoid!

This article discusses and gives many examples of how statistics are often misinterpreted and incorrect analyses are drawn by those who are inexperienced in statistical analysis: 
[Demystifying Statistics: Experts Discuss Common Misunderstandings ](https://academic.oup.com/jnci/article/93/23/1768/2519660)



![](https://images.theconversation.com/files/162827/original/image-20170328-21243-6xrdpk.jpg?ixlib=rb-1.1.0&q=45&auto=format&w=1200&h=1200.0&fit=crop)