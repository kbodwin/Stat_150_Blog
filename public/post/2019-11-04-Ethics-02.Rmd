---
title: "Bias in ML"
author: "beamy_rhino"
date: 2019-11-04
categories: ["Section 01", "Ethics Topic"]
tags: ["Section 01", "Ethics and Bias in Machine Learning: A Technical Study of What Makes Us 'Good'"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We are living in a digital age. Machines have become fully integrated into our daily lives; phones, television, electric toothbrushes, you name it. The use of artificial intelligence in data studies is rapidly increasing. But what are the ethical consequences when this machinery is taken too far? The study “Ethics and Bias in Machine Learning: A Technical Study of What Makes Us ‘Good’” by Ashley Nicole Shadowen examines this ethical dilemma. Read more here!

> "It [machine learning] can sow inequality deeper by hard-coding it into our machines"
> - Ashley Nicole Shadowen

https://academicworks.cuny.edu/cgi/viewcontent.cgi?article=1042&context=jj_etds 
https://becominghuman.ai/how-to-prevent-bias-in-machine-learning-fbd9adf1198

The study “Ethics and Bias in Machine Learning: A Technical Study of What Makes Us 'Good'" by Ashley Nicole Shadowen deals with artificial intelligence. Artificial intelligence is the ability of machines to exhibit human-like decision making in context with their surroundings. People have questioned the ethics behind using AI and try to determine what makes a certain AI product good or not; however, there are many different ways to define “good”. Most have come to conclude that good AI occurs when one cannot tell if they are interacting with a machine or AI. 

However, the study mentions that we don’t quite know if this definition is useful or not. In the world, there is so much bias and outside factors humans consider; a computer can’t do all of that, no matter how well you program it. Machine learning is a part of AI where data is ingested, understood, and integrated into an algorithmic function to make predictions. Basically, the machine is made of what we think to put in, not all the essentials. An example of bias used in this way is the making of the Pokémon Go! app. The goal of the app is to “catch” as many virtual Pokémon as you can, pointing your phone in certain areas where certain Pokémon appear. When deciding where to place the Pokémon, the app developers decided to survey the most common places young white men (the target demographic) went. This made Pokémon not as discoverable in low income places.

One way we have tried to prevent such bias in studies is by conducting extensive contextual validity testing, particularly on algorithms with high legal and ethical impact. Contextual validity testing is ensuring that one’s algorithm is well-founded and corresponds to the real world. This testing is one of the best ways to inform on “ethical corrections”, and is vital in avoiding bias. Since machine learning’s popularity is constantly growing, we want to avoid bias at all costs to make sure accurate results are being produced as much as possible. We put so much faith and trust into what computers tell us that we need to make sure we are getting the right information. However, computers are not always right. Not many people have tried to fix this problem, which is why educating others on this topic is so vital.

An article written by the same author of this study analyzes the fine balance between increasing the use of technology while still remaining ethical (link above). Shadowen states that machine bias can harm human life, often when inappropriate or invalid personal data is used. This makes logical sense; computers do not care about one’s personal information. She goes on to say that “in some cases, it [machine learning] can sow inequality deeper by hard-coding it into our machines”.  Overall, machine learning and AI can be wonderful things when used in the right context. We as data analysts must find the balance between it and good old-fashioned data collection.

![](https://wikimediafoundation.org/news/2018/08/01/wikimedia-joins-partnership-on-ai/)
